{
  "resolvedId": "D:/Project/Project/project-front/vue-user-template-new/node_modules/monaco-editor/esm/vs/editor/common/model/textModelTokens.js",
  "transforms": [
    {
      "name": "vite:load-fallback",
      "result": "/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport * as arrays from '../../../base/common/arrays.js';\nimport { onUnexpectedError } from '../../../base/common/errors.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\nimport { TokenizationRegistry } from '../languages.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { Disposable } from '../../../base/common/lifecycle.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { runWhenIdle } from '../../../base/common/async.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\n/**\n * An array that avoids being sparse by always\n * filling up unused indices with a default value.\n */\nclass ContiguousGrowingArray {\n    constructor(_default) {\n        this._default = _default;\n        this._store = [];\n    }\n    get(index) {\n        if (index < this._store.length) {\n            return this._store[index];\n        }\n        return this._default;\n    }\n    set(index, value) {\n        while (index >= this._store.length) {\n            this._store[this._store.length] = this._default;\n        }\n        this._store[index] = value;\n    }\n    delete(deleteIndex, deleteCount) {\n        if (deleteCount === 0 || deleteIndex >= this._store.length) {\n            return;\n        }\n        this._store.splice(deleteIndex, deleteCount);\n    }\n    insert(insertIndex, insertCount) {\n        if (insertCount === 0 || insertIndex >= this._store.length) {\n            return;\n        }\n        const arr = [];\n        for (let i = 0; i < insertCount; i++) {\n            arr[i] = this._default;\n        }\n        this._store = arrays.arrayInsert(this._store, insertIndex, arr);\n    }\n}\n/**\n * Stores the states at the start of each line and keeps track of which lines\n * must be retokenized. Also uses state equality to quickly validate lines\n * that don't need to be retokenized.\n *\n * For example, when typing on a line, the line gets marked as needing to be tokenized.\n * Once the line is tokenized, the end state is checked for equality against the begin\n * state of the next line. If the states are equal, tokenization doesn't need to run\n * again over the rest of the file. If the states are not equal, the next line gets marked\n * as needing to be tokenized.\n */\nexport class TokenizationStateStore {\n    constructor(tokenizationSupport, initialState) {\n        this.tokenizationSupport = tokenizationSupport;\n        this.initialState = initialState;\n        /**\n         * `lineBeginState[i]` contains the begin state used to tokenize line number `i + 1`.\n         */\n        this._lineBeginState = new ContiguousGrowingArray(null);\n        /**\n         * `lineNeedsTokenization[i]` describes if line number `i + 1` needs to be tokenized.\n         */\n        this._lineNeedsTokenization = new ContiguousGrowingArray(true);\n        this._firstLineNeedsTokenization = 0;\n        this._lineBeginState.set(0, this.initialState);\n    }\n    get invalidLineStartIndex() {\n        return this._firstLineNeedsTokenization;\n    }\n    markMustBeTokenized(lineIndex) {\n        this._lineNeedsTokenization.set(lineIndex, true);\n        this._firstLineNeedsTokenization = Math.min(this._firstLineNeedsTokenization, lineIndex);\n    }\n    getBeginState(lineIndex) {\n        return this._lineBeginState.get(lineIndex);\n    }\n    setEndState(linesLength, lineIndex, endState) {\n        this._lineNeedsTokenization.set(lineIndex, false);\n        this._firstLineNeedsTokenization = lineIndex + 1;\n        // Check if this was the last line\n        if (lineIndex === linesLength - 1) {\n            return;\n        }\n        // Check if the end state has changed\n        const previousEndState = this._lineBeginState.get(lineIndex + 1);\n        if (previousEndState === null || !endState.equals(previousEndState)) {\n            this._lineBeginState.set(lineIndex + 1, endState);\n            this.markMustBeTokenized(lineIndex + 1);\n            return;\n        }\n        // Perhaps we can skip tokenizing some lines...\n        let i = lineIndex + 1;\n        while (i < linesLength) {\n            if (this._lineNeedsTokenization.get(i)) {\n                break;\n            }\n            i++;\n        }\n        this._firstLineNeedsTokenization = i;\n    }\n    //#region Editing\n    applyEdits(range, eolCount) {\n        this.markMustBeTokenized(range.startLineNumber - 1);\n        this._lineBeginState.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n        this._lineNeedsTokenization.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n        this._lineBeginState.insert(range.startLineNumber, eolCount);\n        this._lineNeedsTokenization.insert(range.startLineNumber, eolCount);\n    }\n}\nexport class TextModelTokenization extends Disposable {\n    constructor(_textModel, _languageIdCodec) {\n        super();\n        this._textModel = _textModel;\n        this._languageIdCodec = _languageIdCodec;\n        this._isScheduled = false;\n        this._isDisposed = false;\n        this._tokenizationStateStore = null;\n        this._register(TokenizationRegistry.onDidChange((e) => {\n            const languageId = this._textModel.getLanguageId();\n            if (e.changedLanguages.indexOf(languageId) === -1) {\n                return;\n            }\n            this._resetTokenizationState();\n            this._textModel.clearTokens();\n        }));\n        this._resetTokenizationState();\n    }\n    dispose() {\n        this._isDisposed = true;\n        super.dispose();\n    }\n    //#region TextModel events\n    handleDidChangeContent(e) {\n        if (e.isFlush) {\n            this._resetTokenizationState();\n            return;\n        }\n        if (this._tokenizationStateStore) {\n            for (let i = 0, len = e.changes.length; i < len; i++) {\n                const change = e.changes[i];\n                const [eolCount] = countEOL(change.text);\n                this._tokenizationStateStore.applyEdits(change.range, eolCount);\n            }\n        }\n        this._beginBackgroundTokenization();\n    }\n    handleDidChangeAttached() {\n        this._beginBackgroundTokenization();\n    }\n    handleDidChangeLanguage(e) {\n        this._resetTokenizationState();\n        this._textModel.clearTokens();\n    }\n    //#endregion\n    _resetTokenizationState() {\n        const [tokenizationSupport, initialState] = initializeTokenization(this._textModel);\n        if (tokenizationSupport && initialState) {\n            this._tokenizationStateStore = new TokenizationStateStore(tokenizationSupport, initialState);\n        }\n        else {\n            this._tokenizationStateStore = null;\n        }\n        this._beginBackgroundTokenization();\n    }\n    _beginBackgroundTokenization() {\n        if (this._isScheduled || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n            return;\n        }\n        this._isScheduled = true;\n        runWhenIdle((deadline) => {\n            this._isScheduled = false;\n            this._backgroundTokenizeWithDeadline(deadline);\n        });\n    }\n    /**\n     * Tokenize until the deadline occurs, but try to yield every 1-2ms.\n     */\n    _backgroundTokenizeWithDeadline(deadline) {\n        // Read the time remaining from the `deadline` immediately because it is unclear\n        // if the `deadline` object will be valid after execution leaves this function.\n        const endTime = Date.now() + deadline.timeRemaining();\n        const execute = () => {\n            if (this._isDisposed || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n                // disposed in the meantime or detached or finished\n                return;\n            }\n            this._backgroundTokenizeForAtLeast1ms();\n            if (Date.now() < endTime) {\n                // There is still time before reaching the deadline, so yield to the browser and then\n                // continue execution\n                setTimeout0(execute);\n            }\n            else {\n                // The deadline has been reached, so schedule a new idle callback if necessary\n                this._beginBackgroundTokenization();\n            }\n        };\n        execute();\n    }\n    /**\n     * Tokenize for at least 1ms.\n     */\n    _backgroundTokenizeForAtLeast1ms() {\n        const lineCount = this._textModel.getLineCount();\n        const builder = new ContiguousMultilineTokensBuilder();\n        const sw = StopWatch.create(false);\n        do {\n            if (sw.elapsed() > 1) {\n                // the comparison is intentionally > 1 and not >= 1 to ensure that\n                // a full millisecond has elapsed, given how microseconds are rounded\n                // to milliseconds\n                break;\n            }\n            const tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n            if (tokenizedLineNumber >= lineCount) {\n                break;\n            }\n        } while (this._hasLinesToTokenize());\n        this._textModel.setTokens(builder.finalize(), !this._hasLinesToTokenize());\n    }\n    tokenizeViewport(startLineNumber, endLineNumber) {\n        const builder = new ContiguousMultilineTokensBuilder();\n        this._tokenizeViewport(builder, startLineNumber, endLineNumber);\n        this._textModel.setTokens(builder.finalize(), !this._hasLinesToTokenize());\n    }\n    reset() {\n        this._resetTokenizationState();\n        this._textModel.clearTokens();\n    }\n    forceTokenization(lineNumber) {\n        const builder = new ContiguousMultilineTokensBuilder();\n        this._updateTokensUntilLine(builder, lineNumber);\n        this._textModel.setTokens(builder.finalize(), !this._hasLinesToTokenize());\n    }\n    getTokenTypeIfInsertingCharacter(position, character) {\n        if (!this._tokenizationStateStore) {\n            return 0 /* Other */;\n        }\n        this.forceTokenization(position.lineNumber);\n        const lineStartState = this._tokenizationStateStore.getBeginState(position.lineNumber - 1);\n        if (!lineStartState) {\n            return 0 /* Other */;\n        }\n        const languageId = this._textModel.getLanguageId();\n        const lineContent = this._textModel.getLineContent(position.lineNumber);\n        // Create the text as if `character` was inserted\n        const text = (lineContent.substring(0, position.column - 1)\n            + character\n            + lineContent.substring(position.column - 1));\n        const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n        const lineTokens = new LineTokens(r.tokens, text, this._languageIdCodec);\n        if (lineTokens.getCount() === 0) {\n            return 0 /* Other */;\n        }\n        const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n        return lineTokens.getStandardTokenType(tokenIndex);\n    }\n    tokenizeLineWithEdit(position, length, newText) {\n        const lineNumber = position.lineNumber;\n        const column = position.column;\n        if (!this._tokenizationStateStore) {\n            return null;\n        }\n        this.forceTokenization(lineNumber);\n        const lineStartState = this._tokenizationStateStore.getBeginState(lineNumber - 1);\n        if (!lineStartState) {\n            return null;\n        }\n        const curLineContent = this._textModel.getLineContent(lineNumber);\n        const newLineContent = curLineContent.substring(0, column - 1)\n            + newText + curLineContent.substring(column - 1 + length);\n        const languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n        const result = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, newLineContent, true, lineStartState);\n        const lineTokens = new LineTokens(result.tokens, newLineContent, this._languageIdCodec);\n        return lineTokens;\n    }\n    isCheapToTokenize(lineNumber) {\n        if (!this._tokenizationStateStore) {\n            return true;\n        }\n        const firstInvalidLineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n        if (lineNumber > firstInvalidLineNumber) {\n            return false;\n        }\n        if (lineNumber < firstInvalidLineNumber) {\n            return true;\n        }\n        if (this._textModel.getLineLength(lineNumber) < 2048 /* CHEAP_TOKENIZATION_LENGTH_LIMIT */) {\n            return true;\n        }\n        return false;\n    }\n    _hasLinesToTokenize() {\n        if (!this._tokenizationStateStore) {\n            return false;\n        }\n        return (this._tokenizationStateStore.invalidLineStartIndex < this._textModel.getLineCount());\n    }\n    _tokenizeOneInvalidLine(builder) {\n        if (!this._tokenizationStateStore || !this._hasLinesToTokenize()) {\n            return this._textModel.getLineCount() + 1;\n        }\n        const lineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n        this._updateTokensUntilLine(builder, lineNumber);\n        return lineNumber;\n    }\n    _updateTokensUntilLine(builder, lineNumber) {\n        if (!this._tokenizationStateStore) {\n            return;\n        }\n        const languageId = this._textModel.getLanguageId();\n        const linesLength = this._textModel.getLineCount();\n        const endLineIndex = lineNumber - 1;\n        // Validate all states up to and including endLineIndex\n        for (let lineIndex = this._tokenizationStateStore.invalidLineStartIndex; lineIndex <= endLineIndex; lineIndex++) {\n            const text = this._textModel.getLineContent(lineIndex + 1);\n            const lineStartState = this._tokenizationStateStore.getBeginState(lineIndex);\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n            builder.add(lineIndex + 1, r.tokens);\n            this._tokenizationStateStore.setEndState(linesLength, lineIndex, r.endState);\n            lineIndex = this._tokenizationStateStore.invalidLineStartIndex - 1; // -1 because the outer loop increments it\n        }\n    }\n    _tokenizeViewport(builder, startLineNumber, endLineNumber) {\n        if (!this._tokenizationStateStore) {\n            // nothing to do\n            return;\n        }\n        if (endLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n            // nothing to do\n            return;\n        }\n        if (startLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n            // tokenization has reached the viewport start...\n            this._updateTokensUntilLine(builder, endLineNumber);\n            return;\n        }\n        let nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(startLineNumber);\n        const fakeLines = [];\n        let initialState = null;\n        for (let i = startLineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n            const newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n            if (newNonWhitespaceIndex === 0) {\n                continue;\n            }\n            if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n                initialState = this._tokenizationStateStore.getBeginState(i - 1);\n                if (initialState) {\n                    break;\n                }\n                fakeLines.push(this._textModel.getLineContent(i));\n                nonWhitespaceColumn = newNonWhitespaceIndex;\n            }\n        }\n        if (!initialState) {\n            initialState = this._tokenizationStateStore.initialState;\n        }\n        const languageId = this._textModel.getLanguageId();\n        let state = initialState;\n        for (let i = fakeLines.length - 1; i >= 0; i--) {\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, fakeLines[i], false, state);\n            state = r.endState;\n        }\n        for (let lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n            const text = this._textModel.getLineContent(lineNumber);\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, state);\n            builder.add(lineNumber, r.tokens);\n            this._tokenizationStateStore.markMustBeTokenized(lineNumber - 1);\n            state = r.endState;\n        }\n    }\n}\nfunction initializeTokenization(textModel) {\n    if (textModel.isTooLargeForTokenization()) {\n        return [null, null];\n    }\n    const tokenizationSupport = TokenizationRegistry.get(textModel.getLanguageId());\n    if (!tokenizationSupport) {\n        return [null, null];\n    }\n    let initialState;\n    try {\n        initialState = tokenizationSupport.getInitialState();\n    }\n    catch (e) {\n        onUnexpectedError(e);\n        return [null, null];\n    }\n    return [tokenizationSupport, initialState];\n}\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n    let r = null;\n    if (tokenizationSupport) {\n        try {\n            r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n        }\n        catch (e) {\n            onUnexpectedError(e);\n        }\n    }\n    if (!r) {\n        r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n    }\n    LineTokens.convertToEndOffset(r.tokens, text.length);\n    return r;\n}\n",
      "start": 1711096856535,
      "end": 1711096856627,
      "sourcemaps": null
    },
    {
      "name": "nuxt:layer-aliasing",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "pre"
    },
    {
      "name": "nuxt:server-devonly:transform",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "pre"
    },
    {
      "name": "nuxt:client-fallback-auto-id",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "pre"
    },
    {
      "name": "vite:css",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:esbuild",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:json",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:worker",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:vue",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:vue-jsx",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "replace",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "nuxt:remove-plugin-metadata",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "nuxt:chunk-error",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "nuxt:components:imports",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "replace",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "ssr-styles",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:define",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:css-post",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:build-html",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:worker-import-meta-url",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "vite:asset-import-meta-url",
      "start": 1711096856627,
      "end": 1711096856627,
      "order": "normal"
    },
    {
      "name": "commonjs",
      "start": 1711096856627,
      "end": 1711096856628,
      "order": "normal"
    },
    {
      "name": "vite:dynamic-import-vars",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "normal"
    },
    {
      "name": "vite:import-glob",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "normal"
    },
    {
      "name": "nuxt:composable-keys",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "nuxt:imports-transform",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "unctx:transform",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "nuxt:pages-macros-transform",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "nuxt:runtime-paths-dep",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "nuxt:route-injection-plugin",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "nuxt:components-loader",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "nuxt:tree-shake-composables:transform",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "post"
    },
    {
      "name": "vite:build-import-analysis",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "normal"
    },
    {
      "name": "vite:reporter",
      "start": 1711096856628,
      "end": 1711096856628,
      "order": "normal"
    }
  ]
}
